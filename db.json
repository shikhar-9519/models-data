
{
  "models": [
    {
      "id": 1,
      "name": "GPT-3",
      "category": "Natural Language Processing",
      "description": "GPT-3 (Generative Pre-trained Transformer 3) is a state-of-the-art language model developed by OpenAI. It is capable of generating human-like text based on the input provided to it.",
      "provider": "OpenAI",
      "example_code": "import openai\n\nopenai.Completion.create(\n  model=\"text-davinci-003\",\n  prompt=\"Translate the following English text to French: 'Hello, how are you?'\",\n  engine=\"davinci\",\n  max_tokens=60\n)",
      "use_cases": [
        "Text generation",
        "Language translation",
        "Content summarization"
      ]
    },
    {
      "id": 2,
      "name": "BERT",
      "category": "Natural Language Processing",
      "description": "BERT (Bidirectional Encoder Representations from Transformers) is a pre-trained language representation model developed by Google. It is designed to understand the context of words in a sentence.",
      "provider": "Google",
      "example_code": "from transformers import BertTokenizer, BertForMaskedLM\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForMaskedLM.from_pretrained('bert-base-uncased')\n\ninputs = tokenizer(\"The capital of France is [MASK].\", return_tensors=\"pt\")\nlabels = tokenizer(\"The capital of France is Paris.\", return_tensors=\"pt\")[\"input_ids\"]\n\noutputs = model(**inputs, labels=labels)\nloss = outputs.loss\nlogits = outputs.logits",
      "use_cases": [
        "Text classification",
        "Named entity recognition",
        "Question answering"
      ]
    },
    {
      "id": 3,
      "name": "YOLOv4",
      "category": "Computer Vision",
      "description": "YOLOv4 (You Only Look Once version 4) is a real-time object detection system. It is highly efficient and accurate, making it suitable for various applications such as surveillance and autonomous vehicles.",
      "provider": "Alexey Bochkovskiy et al.",
      "example_code": "import cv2\nimport numpy as np\n\nnet = cv2.dnn.readNet(\"yolov4.weights\", \"yolov4.cfg\")\nlayer_names = net.getLayerNames()\noutput_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n\n# Load image\nimg = cv2.imread(\"image.jpg\")\nheight, width, channels = img.shape\n\n# Detecting objects\nblob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\nnet.setInput(blob)\nouts = net.forward(output_layers)\n\n# Show results\nfor out in outs:\n    for detection in out:\n        scores = detection[5:]\n        class_id = np.argmax(scores)\n        confidence = scores[class_id]\n        if confidence > 0.5:\n            # Object detected\n            center_x = int(detection[0] * width)\n            center_y = int(detection[1] * height)\n            w = int(detection[2] * width)\n            h = int(detection[3] * height)\n            # Draw bounding box\n            cv2.rectangle(img, (center_x - w // 2, center_y - h // 2), (center_x + w // 2, center_y + h // 2), (0, 255, 0), 2)\n\n# Show image with bounding boxes\ncv2.imshow(\"Object Detection\", img)\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
      "use_cases": [
        "Object detection",
        "Traffic monitoring",
        "Retail analytics"
      ]
    },
    {
      "id": 4,
      "name": "T5",
      "category": "Natural Language Processing",
      "description": "T5 (Text-To-Text Transfer Transformer) is a transformer-based model developed by Google Research. It is trained in a text-to-text setting, where it can perform various tasks by converting them into text-to-text format.",
      "provider": "Google",
      "example_code": "from transformers import T5ForConditionalGeneration, T5Tokenizer\n\nmodel = T5ForConditionalGeneration.from_pretrained('t5-small')\ntokenizer = T5Tokenizer.from_pretrained('t5-small')\n\ntext = 'translate English to French: Hello, how are you?'\ninput_ids = tokenizer.encode(text, return_tensors='pt')\noutputs = model.generate(input_ids, max_length=100, num_beams=4, early_stopping=True)\noutput_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(output_text)",
      "use_cases": [
        "Text translation",
        "Text summarization",
        "Question answering"
      ]
    },
    {
      "id": 5,
      "name": "ResNet",
      "category": "Computer Vision",
      "description": "ResNet (Residual Neural Network) is a deep neural network architecture developed by Microsoft Research. It is widely used for image classification tasks.",
      "provider": "Microsoft Research",
      "example_code": "import torchvision.models as models\nimport torch\nfrom PIL import Image\nfrom torchvision import transforms\n\n# Load pre-trained ResNet model\nresnet = models.resnet50(pretrained=True)\n\n# Preprocess image\nimage = Image.open('image.jpg')\npreprocess = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\nimage = preprocess(image).unsqueeze(0)\n\n# Inference\noutput = resnet(image)\nprint(torch.argmax(output, dim=1))",
      "use_cases": [
        "Image classification",
        "Feature extraction",
        "Object recognition"
      ]
    },
    {
      "id": 6,
      "name": "BERTini",
      "category": "Natural Language Processing",
      "description": "BERTini is a lightweight variant of the BERT model optimized for mobile and edge devices. It provides fast and efficient language understanding.",
      "provider": "BERTini Inc.",
      "example_code": "from transformers import BertTokenizer, BertForMaskedLM\n\ntokenizer = BertTokenizer.from_pretrained('bertini-base-uncased')\nmodel = BertForMaskedLM.from_pretrained('bertini-base-uncased')\n\ninputs = tokenizer(\"The capital of France is [MASK].\", return_tensors=\"pt\")\nlabels = tokenizer(\"The capital of France is Paris.\", return_tensors=\"pt\")[\"input_ids\"]\n\noutputs = model(**inputs, labels=labels)\nloss = outputs.loss\nlogits = outputs.logits",
      "use_cases": [
        "Text classification",
        "Named entity recognition",
        "Question answering"
      ]
    },
    {
      "id": 7,
      "name": "DALL-E",
      "category": "Artificial Intelligence",
      "description": "DALL-E is a neural network-based image generation model developed by OpenAI. It is trained to generate images from textual descriptions.",
      "provider": "OpenAI",
      "example_code": "import openai\n\nresponse = openai.Image.create(\n  prompt=\"A painting of a sunset over a lake with mountains in the background\",\n  engine=\"davinci\",\n  max_tokens=50\n)\n\nprint(response)",
      "use_cases": [
        "Image generation",
        "Creative AI",
        "Artistic design"
      ]
    },
    {
      "id": 8,
      "name": "MobileNet",
      "category": "Computer Vision",
      "description": "MobileNet is a family of efficient convolutional neural networks designed for mobile and embedded vision applications. They provide high accuracy with low computational cost.",
      "provider": "Google",
      "example_code": "import torch\nfrom torchvision import models\n\n# Load pre-trained MobileNetV2 model\nmobilenet = models.mobilenet_v2(pretrained=True)\n\n# Set model to evaluation mode\nmobilenet.eval()\n\n# Generate random input tensor\ninput_tensor = torch.rand(1, 3, 224, 224)\n\n# Perform inference\noutput = mobilenet(input_tensor)\n\n# Print output\nprint(output)",
      "use_cases": [
        "Image classification",
        "Object detection",
        "Scene recognition"
      ]
    },
    {
      "id": 9,
      "name": "VGG16",
      "category": "Computer Vision",
      "description": "VGG16 is a convolutional neural network architecture developed by the Visual Geometry Group at the University of Oxford. It has 16 layers and is known for its simplicity and effectiveness in image classification tasks.",
      "provider": "University of Oxford",
      "example_code": "import openai\n\nresponse = openai.Image.create(\n  prompt=\"A painting of a sunset over a lake with mountains in the background\",\n  engine=\"davinci\",\n  max_tokens=50\n)\n\nprint(response)",
      "use_cases": [
        "Image generation",
        "Creative AI",
        "Artistic design"
      ]
    }
],
"featuredModels": [
  {
    "id": 4,
    "name": "T5",
    "category": "Natural Language Processing",
    "description": "T5 (Text-To-Text Transfer Transformer) is a transformer-based model developed by Google Research. It is trained in a text-to-text setting, where it can perform various tasks by converting them into text-to-text format.",
    "provider": "Google",
    "example_code": "from transformers import T5ForConditionalGeneration, T5Tokenizer\n\nmodel = T5ForConditionalGeneration.from_pretrained('t5-small')\ntokenizer = T5Tokenizer.from_pretrained('t5-small')\n\ntext = 'translate English to French: Hello, how are you?'\ninput_ids = tokenizer.encode(text, return_tensors='pt')\noutputs = model.generate(input_ids, max_length=100, num_beams=4, early_stopping=True)\noutput_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(output_text)",
    "use_cases": [
      "Text translation",
      "Text summarization",
      "Question answering"
    ]
  },
  {
    "id": 5,
    "name": "ResNet",
    "category": "Computer Vision",
    "description": "ResNet (Residual Neural Network) is a deep neural network architecture developed by Microsoft Research. It is widely used for image classification tasks.",
    "provider": "Microsoft Research",
    "example_code": "import torchvision.models as models\nimport torch\nfrom PIL import Image\nfrom torchvision import transforms\n\n# Load pre-trained ResNet model\nresnet = models.resnet50(pretrained=True)\n\n# Preprocess image\nimage = Image.open('image.jpg')\npreprocess = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\nimage = preprocess(image).unsqueeze(0)\n\n# Inference\noutput = resnet(image)\nprint(torch.argmax(output, dim=1))",
    "use_cases": [
      "Image classification",
      "Feature extraction",
      "Object recognition"
    ]
  },
  {
    "id": 6,
    "name": "BERTini",
    "category": "Natural Language Processing",
    "description": "BERTini is a lightweight variant of the BERT model optimized for mobile and edge devices. It provides fast and efficient language understanding.",
    "provider": "BERTini Inc.",
    "example_code": "from transformers import BertTokenizer, BertForMaskedLM\n\ntokenizer = BertTokenizer.from_pretrained('bertini-base-uncased')\nmodel = BertForMaskedLM.from_pretrained('bertini-base-uncased')\n\ninputs = tokenizer(\"The capital of France is [MASK].\", return_tensors=\"pt\")\nlabels = tokenizer(\"The capital of France is Paris.\", return_tensors=\"pt\")[\"input_ids\"]\n\noutputs = model(**inputs, labels=labels)\nloss = outputs.loss\nlogits = outputs.logits",
    "use_cases": [
      "Text classification",
      "Named entity recognition",
      "Question answering"
    ]
  },
  {
    "id": 7,
    "name": "DALL-E",
    "category": "Artificial Intelligence",
    "description": "DALL-E is a neural network-based image generation model developed by OpenAI. It is trained to generate images from textual descriptions.",
    "provider": "OpenAI",
    "example_code": "import openai\n\nresponse = openai.Image.create(\n  prompt=\"A painting of a sunset over a lake with mountains in the background\",\n  engine=\"davinci\",\n  max_tokens=50\n)\n\nprint(response)",
    "use_cases": [
      "Image generation",
      "Creative AI",
      "Artistic design"
    ]
  }
]
}
